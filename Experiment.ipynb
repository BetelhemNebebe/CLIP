{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import clip\n",
    "import wav2clip\n",
    "from moviepy.audio.AudioClip import AudioArrayClip\n",
    "import moviepy.video.io.VideoFileClip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_list(dir_path):\n",
    "    file_list = []\n",
    "\n",
    "    # Iterate directory\n",
    "    for path in os.listdir(dir_path):\n",
    "        # check if current path is a file\n",
    "        if os.path.isfile(os.path.join(dir_path, path)):\n",
    "            file_list.append(path)\n",
    "            \n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_avg_frame(video_path):\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "\n",
    "    success = True\n",
    "    count = 0\n",
    "    while success:\n",
    "        success, frames = video.read()\n",
    "        sum_frame = sum_frame + frames\n",
    "        count = count + 1\n",
    "\n",
    "    mean_frame = sum_frame/count\n",
    "    return mean_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio(video_path):\n",
    "    video = moviepy.video.io.VideoFileClip(video_path)\n",
    "    audio = video.audio\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "dir_path = r'C:\\\\Masters\\\\semester_3\\\\Project_1\\\\data\\\\ERB3_Stimuli'\n",
    "file_list = get_file_list(dir_path)\n",
    "img_features = []\n",
    "\n",
    "for file in file_list:\n",
    "    #Extract a mean image for every video clip\n",
    "    image = extract_avg_frame(file)\n",
    "    audio = extract_audio(file)\n",
    "    model_vid, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "    model_aud = wav2clip.get_model()\n",
    "    image = preprocess(image).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        image_features = model_vid.encode_image(image)\n",
    "        audio_embeddings = wav2clip.embed_audio(audio, model_aud)\n",
    "        img_features.append(image_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clip_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9f9398c0f8738c578d24091be890bc44e69c4e5be3f0f7ee50f3d4e45880647"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
